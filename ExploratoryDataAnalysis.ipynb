{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instacart Market Basket Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Load the Data:\n",
    "- Load the CSV files into pandas DataFrames.\n",
    "- Check for missing values and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_aisles = pd.read_csv('aisles.csv')\n",
    "df_departments = pd.read_csv('departments.csv')\n",
    "df_order_products_prior = pd.read_csv('order_products__prior.csv')\n",
    "df_order_products_train = pd.read_csv('order_products__train.csv')\n",
    "df_orders = pd.read_csv('orders.csv')\n",
    "df_products = pd.read_csv('products.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the empty value in days_since_prior_order to 0 as it is the first order for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0    2539329        1    prior             1          2                  8   \n",
      "1    2398795        1    prior             2          3                  7   \n",
      "2     473747        1    prior             3          3                 12   \n",
      "3    2254736        1    prior             4          4                  7   \n",
      "4     431534        1    prior             5          4                 15   \n",
      "5    3367565        1    prior             6          2                  7   \n",
      "6     550135        1    prior             7          1                  9   \n",
      "7    3108588        1    prior             8          1                 14   \n",
      "8    2295261        1    prior             9          1                 16   \n",
      "9    2550362        1    prior            10          4                  8   \n",
      "10   1187899        1    train            11          4                  8   \n",
      "11   2168274        2    prior             1          2                 11   \n",
      "12   1501582        2    prior             2          5                 10   \n",
      "13   1901567        2    prior             3          1                 10   \n",
      "14    738281        2    prior             4          2                 10   \n",
      "15   1673511        2    prior             5          3                 11   \n",
      "16   1199898        2    prior             6          2                  9   \n",
      "17   3194192        2    prior             7          2                 12   \n",
      "18    788338        2    prior             8          1                 15   \n",
      "19   1718559        2    prior             9          2                  9   \n",
      "20   1447487        2    prior            10          1                 11   \n",
      "21   1402090        2    prior            11          1                 10   \n",
      "22   3186735        2    prior            12          1                  9   \n",
      "23   3268552        2    prior            13          4                 11   \n",
      "24    839880        2    prior            14          3                 10   \n",
      "25   1492625        2    train            15          1                 11   \n",
      "26   1374495        3    prior             1          1                 14   \n",
      "27    444309        3    prior             2          3                 19   \n",
      "28   3002854        3    prior             3          3                 16   \n",
      "29   2037211        3    prior             4          2                 18   \n",
      "30   2710558        3    prior             5          0                 17   \n",
      "31   1972919        3    prior             6          0                 16   \n",
      "32   1839752        3    prior             7          0                 15   \n",
      "33   3225766        3    prior             8          0                 17   \n",
      "34   3160850        3    prior             9          0                 16   \n",
      "35    676467        3    prior            10          3                 16   \n",
      "36    521107        3    prior            11          0                 18   \n",
      "37   1402502        3    prior            12          1                 15   \n",
      "38   2774568        3     test            13          5                 15   \n",
      "39   3343014        4    prior             1          6                 11   \n",
      "40   2030307        4    prior             2          4                 11   \n",
      "41    691089        4    prior             3          4                 15   \n",
      "42     94891        4    prior             4          5                 13   \n",
      "43   2557754        4    prior             5          5                 13   \n",
      "44    329954        4     test             6          3                 12   \n",
      "45   2717275        5    prior             1          3                 12   \n",
      "46   1909121        5    prior             2          0                 16   \n",
      "47   2267326        5    prior             3          3                 18   \n",
      "48    157374        5    prior             4          1                 18   \n",
      "49   2196797        5    train             5          0                 11   \n",
      "\n",
      "    days_since_prior_order  \n",
      "0                      2.0  \n",
      "1                     15.0  \n",
      "2                     21.0  \n",
      "3                     29.0  \n",
      "4                     28.0  \n",
      "5                     19.0  \n",
      "6                     20.0  \n",
      "7                     14.0  \n",
      "8                      0.0  \n",
      "9                     30.0  \n",
      "10                    14.0  \n",
      "11                     2.0  \n",
      "12                    10.0  \n",
      "13                     3.0  \n",
      "14                     8.0  \n",
      "15                     8.0  \n",
      "16                    13.0  \n",
      "17                    14.0  \n",
      "18                    27.0  \n",
      "19                     8.0  \n",
      "20                     6.0  \n",
      "21                    30.0  \n",
      "22                    28.0  \n",
      "23                    30.0  \n",
      "24                    13.0  \n",
      "25                    30.0  \n",
      "26                     1.0  \n",
      "27                     9.0  \n",
      "28                    21.0  \n",
      "29                    20.0  \n",
      "30                    12.0  \n",
      "31                     7.0  \n",
      "32                     7.0  \n",
      "33                     7.0  \n",
      "34                     7.0  \n",
      "35                    17.0  \n",
      "36                    11.0  \n",
      "37                    15.0  \n",
      "38                    11.0  \n",
      "39                     6.0  \n",
      "40                    19.0  \n",
      "41                    21.0  \n",
      "42                    15.0  \n",
      "43                     0.0  \n",
      "44                    30.0  \n",
      "45                     3.0  \n",
      "46                    11.0  \n",
      "47                    10.0  \n",
      "48                    19.0  \n",
      "49                     6.0  \n"
     ]
    }
   ],
   "source": [
    "null_index = df_orders.loc[df_orders['days_since_prior_order'].isnull()].index\n",
    "df_orders.loc[df_orders['days_since_prior_order'].isnull(),'days_since_prior_order'] = 0\n",
    "#df_orders['days_since_prior_order'] = [row['order_dow'] if row['order_number'] == 1 else row['days_since_prior_order'] for _, row in df_orders.iterrows()]\n",
    "#remove user_id = 0 as all its data are 0\n",
    "#i = df_orders[(df_orders.user_id == 0)].index\n",
    "#df_orders.drop(i, inplace = True)\n",
    "print(df_orders.head(50))\n",
    "#df_orders.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge order_products prior and training tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_order_products_train.copy()\n",
    "temp.insert(0,'istraining', 1)\n",
    "df_order_products = df_order_products_prior.copy()\n",
    "df_order_products.insert(0,'istraining', 0)\n",
    "frames = [df_order_products, temp]\n",
    "df_order_products = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert datatypes\n",
    "#aisle\n",
    "df_aisles['aisle_id'] = df_aisles['aisle_id'].astype(int)\n",
    "df_aisles['aisle'] = df_aisles['aisle'].astype(str)\n",
    "#df_departments\n",
    "df_departments['department_id'] = df_departments['department_id'].astype(int)\n",
    "df_departments['department'] = df_departments['department'].astype(str)\n",
    "#df_products\n",
    "df_products['product_id'] = df_products['product_id'].astype(int)\n",
    "df_products['product_name'] = df_products['product_name'].astype(str)\n",
    "df_products['aisle_id'] = df_products['aisle_id'].astype(int)\n",
    "df_products['department_id'] = df_products['department_id'].astype(int)\n",
    "#df_order_products\n",
    "df_order_products['product_id'] = df_order_products['product_id'].astype(int)\n",
    "df_order_products['order_id'] = df_order_products['order_id'].astype(int)\n",
    "df_order_products['add_to_cart_order'] = df_order_products['add_to_cart_order'].astype(int)\n",
    "df_order_products['reordered'] = df_order_products['reordered'].astype(bool)\n",
    "df_order_products['istraining'] = df_order_products['istraining'].astype(bool)\n",
    "#df_orders\n",
    "df_orders['order_id'] = df_orders['order_id'].astype(int)\n",
    "df_orders['user_id'] = df_orders['user_id'].astype(int)\n",
    "df_orders['eval_set'] = df_orders['eval_set'].astype(str)\n",
    "df_orders['order_number'] = df_orders['order_number'].astype(int)\n",
    "df_orders['order_dow'] = df_orders['order_dow'].astype(int)\n",
    "df_orders['order_hour_of_day'] = df_orders['order_hour_of_day'].astype(int)\n",
    "df_orders['days_since_prior_order'] = df_orders['days_since_prior_order'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_array = [\n",
    "    df_aisles,\n",
    "    df_departments,\n",
    "    df_order_products,\n",
    "    df_orders,\n",
    "    df_products\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "11         0\n",
       "26         0\n",
       "39         0\n",
       "45         0\n",
       "          ..\n",
       "3420930    0\n",
       "3420934    0\n",
       "3421002    0\n",
       "3421019    0\n",
       "3421069    0\n",
       "Name: days_since_prior_order, Length: 206209, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(pd.unique(df_orders['order_number']))\n",
    "#df_orders.order_number.unique()\n",
    "df_orders.iloc[null_index].days_since_prior_order\n",
    "#df_orders.groupby('user_id').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis (EDA)\n",
    "a. Customer Behavior:\n",
    "- Average number of orders per user.\n",
    "- Average time between orders for each user.\n",
    "- Number of orders placed by each customer.\n",
    "- Customer segments based on purchase frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of orders per use = 16.590367054784224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "segment\n",
       "FB    165998\n",
       "OB     35798\n",
       "RB      4413\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "function takes average days between orders and classify customer based on following rules:\n",
    "# Frequent Buyers: Customers who make purchases regularly (e.g.,weekly or monthly)\n",
    "# average days between orders FB < 30\n",
    "# Occasional Buyers: Customers who purchase less frequently (e.g., quarterly).\n",
    "# average days between orders 30 <= OB < 90\n",
    "# Rare Buyers: Customers who make very few purchases (e.g., annually).\n",
    "# average days between orders 90 <= RB \n",
    "'''\n",
    "def customer_segment(avg_days):\n",
    "    if avg_days < 25 :\n",
    "        return 'FB'\n",
    "    elif 25 <= avg_days < 70:\n",
    "        return 'OB'\n",
    "    else:\n",
    "        return 'RB'\n",
    "        \n",
    "#Average number of orders per user = Total number of orders / total number of users\n",
    "no_orders = len(pd.unique(df_orders['order_id']))\n",
    "no_users = len(pd.unique(df_orders['user_id']))\n",
    "avg_no = no_orders/no_users\n",
    "print(f\"Average number of orders per use = {avg_no}\")\n",
    "\n",
    "#Average time between orders for each user\n",
    "df_customer_time = df_orders.groupby('user_id').agg({\n",
    "    'order_id':'count',\n",
    "    'order_hour_of_day':'sum'\n",
    "}).round(2)\n",
    "df_customer_time[\"avg_time\"] = df_customer_time[\"order_hour_of_day\"] / df_customer_time[\"order_id\"]\n",
    "df_customer_time.head()\n",
    "\n",
    "#Number of orders placed by each customer\n",
    "df_customer_groupby = df_orders.groupby('user_id').agg({\n",
    "    'order_id':'count',\n",
    "    'days_since_prior_order':'mean'\n",
    "}).round(2)\n",
    "\n",
    "#Customer segments based on purchase frequency\n",
    "order_count = list(df_customer_groupby.order_id)\n",
    "\n",
    "df_customer_segment= df_customer_groupby.assign(\n",
    "    segment = [customer_segment(x) for x in order_count]\n",
    ")\n",
    "df_customer_segment.reset_index()\n",
    "df_customer_segment.segment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Product Analysis:\n",
    "- Identify most popular products by frequency.\n",
    "- Determine average order size (number of items per order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average average order size = 9.885497077972092\n"
     ]
    }
   ],
   "source": [
    "#calculate frequency of ordering each product\n",
    "df_order_products.groupby('product_id').agg({'order_id':'count'}).nlargest(10,columns = 'order_id')\n",
    "#Determine average order size (number of items per order).\n",
    "df_order_products.groupby('order_id').agg({'product_id':'mean'})\n",
    "no_orders = len(pd.unique(df_orders['order_id']))\n",
    "no_ordered_products = len(df_order_products)\n",
    "avg_no = no_ordered_products / no_orders\n",
    "print(f\"Average average order size = {avg_no}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Temporal Patterns:\n",
    "- Analyze orders by day of the week and hour of the day.\n",
    "- Explore seasonal trends or patterns in purchasing behavior.\n",
    "- Months with higher order volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'The grouper name date_of_order is not found'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m df_orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_hour_of_day\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#get number of orders per month \u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mdf_orders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGrouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate_of_order\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morder_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#-------------------------------------------#\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#Months with higher order volumes\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#assume start date 01012018 and all useres first order \u001b[39;00m\n\u001b[1;32m     21\u001b[0m df_orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_order\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01/06/2018\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.9/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/grouper.py:1054\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         in_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# create the Grouping\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# allow us to passing the actual Grouping as the gpr\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     ping \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1054\u001b[0m         \u001b[43mGrouping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgroup_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m            \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m            \u001b[49m\u001b[43min_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouping)\n\u001b[1;32m   1065\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m gpr\n\u001b[1;32m   1066\u001b[0m     )\n\u001b[1;32m   1068\u001b[0m     groupings\u001b[38;5;241m.\u001b[39mappend(ping)\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(groupings) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj):\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/grouper.py:579\u001b[0m, in \u001b[0;36mGrouping.__init__\u001b[0;34m(self, index, grouper, obj, level, sort, observed, in_axis, dropna, uniques)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(grouping_vector, Grouper):\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;66;03m# get the new grouper; we already have disambiguated\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# what key/level refer to exactly, don't need to\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# check again as we have by this point converted these\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;66;03m# to an actual value (rather than a pd.Grouper)\u001b[39;00m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     newgrouper, newobj \u001b[38;5;241m=\u001b[39m \u001b[43mgrouping_vector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_grouper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m newobj\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(newgrouper, ops\u001b[38;5;241m.\u001b[39mBinGrouper):\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;66;03m# TODO: can we unwrap this and get a tighter typing\u001b[39;00m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;66;03m#  for self.grouping_vector?\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.9/site-packages/pandas/core/resample.py:2282\u001b[0m, in \u001b[0;36mTimeGrouper._get_grouper\u001b[0;34m(self, obj, validate)\u001b[0m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_grouper\u001b[39m(\n\u001b[1;32m   2279\u001b[0m     \u001b[38;5;28mself\u001b[39m, obj: NDFrameT, validate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[BinGrouper, NDFrameT]:\n\u001b[1;32m   2281\u001b[0m     \u001b[38;5;66;03m# create the resampler and return our binner\u001b[39;00m\n\u001b[0;32m-> 2282\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_resampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39m_grouper, cast(NDFrameT, r\u001b[38;5;241m.\u001b[39mobj)\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.9/site-packages/pandas/core/resample.py:2229\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[0;34m(self, obj, kind)\u001b[0m\n\u001b[1;32m   2210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_resampler\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: NDFrame, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Resampler:\n\u001b[1;32m   2211\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2212\u001b[0m \u001b[38;5;124;03m    Return my resampler or raise if we have an invalid axis.\u001b[39;00m\n\u001b[1;32m   2213\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2227\u001b[0m \n\u001b[1;32m   2228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2229\u001b[0m     _, ax, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_grouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpr_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, DatetimeIndex):\n\u001b[1;32m   2231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeIndexResampler(\n\u001b[1;32m   2232\u001b[0m             obj,\n\u001b[1;32m   2233\u001b[0m             timegrouper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2237\u001b[0m             gpr_index\u001b[38;5;241m=\u001b[39max,\n\u001b[1;32m   2238\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.9/site-packages/pandas/core/resample.py:2529\u001b[0m, in \u001b[0;36mTimeGrouper._set_grouper\u001b[0;34m(self, obj, sort, gpr_index)\u001b[0m\n\u001b[1;32m   2526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_grouper\u001b[39m(\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;28mself\u001b[39m, obj: NDFrameT, sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, gpr_index: Index \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2528\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[NDFrameT, Index, npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m-> 2529\u001b[0m     obj, ax, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_grouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpr_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpr_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2530\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax\u001b[38;5;241m.\u001b[39mdtype, ArrowDtype) \u001b[38;5;129;01mand\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2531\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arrow_dtype \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/grouper.py:380\u001b[0m, in \u001b[0;36mGrouper._set_grouper\u001b[0;34m(self, obj, sort, gpr_index)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_info_axis:\n\u001b[0;32m--> 380\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe grouper name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    381\u001b[0m         ax \u001b[38;5;241m=\u001b[39m Index(obj[key], name\u001b[38;5;241m=\u001b[39mkey)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'The grouper name date_of_order is not found'"
     ]
    }
   ],
   "source": [
    "#Analyze orders by day of the week \n",
    "df_week = df_orders.groupby('order_dow').agg({\n",
    "    'order_id':'count'\n",
    "})\n",
    "df_week.reset_index().nlargest(n=10, columns='order_id')\n",
    "#Analyze orders by hour of the day\n",
    "df_hour = df_orders.groupby('order_hour_of_day').agg({\n",
    "    'order_id':'count'\n",
    "})\n",
    "df_hour.reset_index().nlargest(n=30, columns='order_id')\n",
    "#-------------------------------------------#\n",
    "#Explore seasonal trends or patterns in purchasing behavior.\n",
    "#get describtion of order_dow and order_hour_of_day column\n",
    "df_orders['order_dow'].describe()\n",
    "df_orders['order_hour_of_day'].describe()\n",
    "#get number of orders per month \n",
    "df_orders.groupby([pd.Grouper(key=\"date_of_order\", freq=\"MS\"), \"order_id\"]).count()\n",
    "#-------------------------------------------#\n",
    "#Months with higher order volumes\n",
    "#assume start date 01012018 and all useres first order \n",
    "df_orders['date_of_order'] = pd.to_datetime('01/06/2018')\n",
    "#df_month = df_orders.groupby('user_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "#Months with higher order volumes\n",
    "#assume start date 01012018 and all useres first order \n",
    "df_orders['date_of_order'] = pd.to_datetime('01/06/2018')\n",
    "df_month = df_orders.groupby('user_id')\n",
    "count1 = 0\n",
    "#prev_date = pd.to_datetime('01/01/2018')\n",
    "#current_user = 1\n",
    "count2 =0\n",
    "for user_id, group in df_orders.groupby('user_id'):\n",
    "    prev_date = pd.to_datetime('01/06/2018')\n",
    "    for index, row in group.iterrows():\n",
    "        if row['order_number'] == 1:\n",
    "            prev_date = pd.to_datetime('01/06/2018')+ timedelta(days=row['order_dow'])\n",
    "        else:\n",
    "            prev_date = prev_date + timedelta(days=row['days_since_prior_order'])\n",
    "            \n",
    "        df_orders.loc[((df_orders['order_id'] == row['order_id']) & (df_orders['user_id'] == row['user_id'])),\\\n",
    "        'date_of_order'] = pd.to_datetime(prev_date)\n",
    "\n",
    "\n",
    "\n",
    "df_orders.head()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##ChatGPT code\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "#problem is each user has different start date\n",
    "# Assuming df_orders is already defined\n",
    "df_orders[\"days_since_prior_order\"] = df_orders[\"order_dow\"] \n",
    "# Convert the 'order_dow' to a timedelta relative to '01/06/2018' for first orders\n",
    "df_orders['date_of_order'] = pd.to_datetime('01/06/2018') + pd.to_timedelta(df_orders['order_dow'], unit='D')\n",
    "\n",
    "# Calculate the cumulative sum of 'days_since_prior_order' for each user\n",
    "df_orders['cumulative_days'] = df_orders.groupby('user_id')['days_since_prior_order'].cumsum()\n",
    "\n",
    "# Adjust the date for subsequent orders\n",
    "df_orders['date_of_order'] = df_orders['date_of_order'] + pd.to_timedelta(df_orders['cumulative_days'].fillna(0), unit='D')\n",
    "\n",
    "# Drop the temporary 'cumulative_days' column if it's no longer needed\n",
    "df_orders.drop(columns=['cumulative_days'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>date_of_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2398795</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>2018-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>2018-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>2018-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>2018-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3367565</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>2018-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>550135</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3108588</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2018-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2295261</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2550362</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>2018-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1187899</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2018-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2168274</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1501582</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1901567</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>738281</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2018-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1673511</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1199898</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3194192</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>2018-03-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>788338</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1718559</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2018-04-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
       "0    2539329        1    prior             1          2                  8   \n",
       "1    2398795        1    prior             2          3                  7   \n",
       "2     473747        1    prior             3          3                 12   \n",
       "3    2254736        1    prior             4          4                  7   \n",
       "4     431534        1    prior             5          4                 15   \n",
       "5    3367565        1    prior             6          2                  7   \n",
       "6     550135        1    prior             7          1                  9   \n",
       "7    3108588        1    prior             8          1                 14   \n",
       "8    2295261        1    prior             9          1                 16   \n",
       "9    2550362        1    prior            10          4                  8   \n",
       "10   1187899        1    train            11          4                  8   \n",
       "11   2168274        2    prior             1          2                 11   \n",
       "12   1501582        2    prior             2          5                 10   \n",
       "13   1901567        2    prior             3          1                 10   \n",
       "14    738281        2    prior             4          2                 10   \n",
       "15   1673511        2    prior             5          3                 11   \n",
       "16   1199898        2    prior             6          2                  9   \n",
       "17   3194192        2    prior             7          2                 12   \n",
       "18    788338        2    prior             8          1                 15   \n",
       "19   1718559        2    prior             9          2                  9   \n",
       "\n",
       "    days_since_prior_order date_of_order  \n",
       "0                        0    2018-01-08  \n",
       "1                       15    2018-01-24  \n",
       "2                       21    2018-02-14  \n",
       "3                       29    2018-03-16  \n",
       "4                       28    2018-04-13  \n",
       "5                       19    2018-04-30  \n",
       "6                       20    2018-05-19  \n",
       "7                       14    2018-06-02  \n",
       "8                        0    2018-06-02  \n",
       "9                       30    2018-07-05  \n",
       "10                      14    2018-07-19  \n",
       "11                       0    2018-01-08  \n",
       "12                      10    2018-01-21  \n",
       "13                       3    2018-01-20  \n",
       "14                       8    2018-01-29  \n",
       "15                       8    2018-02-07  \n",
       "16                      13    2018-02-19  \n",
       "17                      14    2018-03-05  \n",
       "18                      27    2018-03-31  \n",
       "19                       8    2018-04-09  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_order</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>532720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>446046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>331791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>283035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>250825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>211206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>175928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>153897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>117485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>85675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               order_id\n",
       "date_of_order          \n",
       "1                532720\n",
       "2                458147\n",
       "3                446046\n",
       "4                374328\n",
       "5                331791\n",
       "6                283035\n",
       "7                250825\n",
       "8                211206\n",
       "9                175928\n",
       "10               153897\n",
       "11               117485\n",
       "12                85675"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "#Months with higher order volumes\n",
    "df_month = df_orders.groupby(df_orders.date_of_order.dt.month).agg({\n",
    "    'order_id':'count'\n",
    "})\n",
    "df_month.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Basket Analysis:\n",
    "- Identify most frequently co-purchased items.\n",
    "- Products often bought together on weekends vs. weekdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify co-purchased items\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "df_order_products_dow = df_order_products.iloc[ : , [1,2] ]\n",
    "df_order_dow = df_orders.iloc[ : , [0,4] ]\n",
    "temp = df_order_products_dow.join(df_order_dow.set_index('order_id'), on='order_id', how = 'left')\n",
    "\n",
    "#temp[temp.order_dow.isin([-np.inf, np.inf])].shape[0]\n",
    "#temp['order_dow'] = temp['order_dow'].astype('int64')\n",
    "\n",
    "#temp dataframe contains order-product-DayOfWeek\n",
    "#get list of products\n",
    "product_lists=[]\n",
    "product_lists=[product_lists.append(list(group['product_id'])) for order_id, group in df_order_products.groupby('order_id')]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>17794</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>40141</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1819</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>43668</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  order_dow\n",
       "0         2       33120          5\n",
       "1         2       28985          5\n",
       "2         2        9327          5\n",
       "3         2       45918          5\n",
       "4         2       30035          5\n",
       "5         2       17794          5\n",
       "6         2       40141          5\n",
       "7         2        1819          5\n",
       "8         2       43668          5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of all combinations of products for each order\n",
    "combinations_list = []\n",
    "for products in product_lists:\n",
    "    combinations_list.extend(combinations(products, 2))\n",
    "\n",
    "# Count the frequency of each combination\n",
    "combination_counts = Counter(combinations_list)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "combination_df = pd.DataFrame(combination_counts.items(), columns=['product_pair', 'frequency'])\n",
    "combination_df = combination_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "print(combination_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "#Products often bought together on weekends vs. weekdays.\n",
    "df_order_products_dow = df_order_products.iloc[ : , [1,2] ]\n",
    "df_order_dow = df_orders.iloc[ : , [0,4] ]\n",
    "temp = df_order_dow.join(df_order_products_dow.set_index('order_id'), on='order_id', how = 'left')\n",
    "df_orders_weekends = temp[temp['order_dow'].isin([0,6])]\n",
    "#get list of products\n",
    "product_lists=[]\n",
    "[product_lists.append(list(group['product_id'])) for order_id, group in df_orders_weekends.groupby('order_id')]\n",
    "# Create a list of all combinations of products for each order\n",
    "combinations_list = []\n",
    "for products in product_lists:\n",
    "    combinations_list.extend(combinations(products, 2))\n",
    "\n",
    "# Count the frequency of each combination\n",
    "combination_counts = Counter(combinations_list)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "combination_df = pd.DataFrame(combination_counts.items(), columns=['product_pair', 'frequency'])\n",
    "combination_df = combination_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "print(combination_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
